---
title: "examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(SemiEstimate)
```

按论文编排的顺序

## toy example

```{r}
# =====================================
# ======= z = x^2 + y^2 + alpha xy=====
# =====================================

Newton = function(beta0, alpha){
  H_GS = matrix(c(2, alpha, alpha, 2), nrow = 2, ncol = 2)
  beta_GS = beta0
  step_GS = 0
  series = NULL
  t0 = Sys.time()
  f = function(x, y) return(c(2*x + alpha*y, 2*y + alpha*x))
  
  while(TRUE){
    bscore = f(beta_GS[1], beta_GS[2])
    if(all(abs(bscore)<1e-7)) break
    beta_GS = beta_GS - solve(H_GS, bscore)
    step_GS = step_GS + 1
    series = rbind(series, beta_GS)
  }
  
  run_time_GS = Sys.time() - t0
  return(list(beta = beta_GS, step = step_GS, run_time = run_time_GS,
              series = series))
}

It = function(beta0, alpha){
  beta_IPS = beta0
  step_IPS = 0
  series_IPS = NULL
  direction = NULL
  t0 = Sys.time()
  while(TRUE){
    x = beta_IPS[1]
    y = beta_IPS[2]
    
    yscore = 2*y + alpha*x
    y = y - yscore/2
    xscore = 2*x + alpha*y
    x = x - xscore/2
    if(all(abs(c(xscore, yscore)) < 1e-7)) break
    beta_IPS = c(x, y)
    series_IPS = rbind(series_IPS, beta_IPS)
    direction = rbind(direction, c(xscore, yscore))
    step_IPS = step_IPS + 1
  }
  
  run_time_IPS = Sys.time() - t0
  return(list(beta = beta_IPS, step = step_IPS, run_time = run_time_IPS, 
              series = series_IPS, direction = direction))
}

Ip = function(beta0, alpha){
  beta_DPS = beta0
  step_DPS = 0
  series_DPS = NULL
  t0 = Sys.time()
  while(TRUE){
    x = beta_DPS[1]
    y = beta_DPS[2]
    yscore = 2*y + alpha*x
    y = y - yscore/2
    xscore = 2*x + alpha*y
    x = x - 2*xscore/(4 - alpha^2)
    if(all(abs(c(xscore, yscore)) < 1e-7)) break
    beta_DPS = c(x, y)
    series_DPS = rbind(series_DPS, beta_DPS)
    step_DPS = step_DPS + 1
  }
  
  run_time_DPS = Sys.time() - t0
  return(list(beta = beta_DPS, step = step_DPS, run_time = run_time_DPS, 
              series = series_DPS))
}
```

```{r}

# 均匀撒点测试
j = 1
step_all = list()
series_all = list()
direction_all = list()
for(k in c(-1.6, -1.1, -0.7, -0.2, 0.2, 0.7, 1.1, 1.6)){
  step = list()
  series = list()
  direction = list()
  length = 10
  theta = seq(0, 2*pi, length.out = length)
  alpha = k
  for(i in 1:10){
    C = i^2
    x = (sqrt(C*(1-alpha/2))*cos(theta) +  sqrt(C*(1+alpha/2))*sin(theta))/sqrt(2- alpha^2/2)
    y = (sqrt(C*(1-alpha/2))*cos(theta) -  sqrt(C*(1+alpha/2))*sin(theta))/sqrt(2- alpha^2/2)
    sub_step = matrix(nrow = 3, ncol = length)
    sub_series = list()
    k1 = list()
    k2 = list()
    k3 = list()
    sub_direction = list()
    for(ii in 1:length){
      beta0 = c(x[ii], y[ii])
      Newton_fit = Newton(beta0, alpha)
      It_fit = It(beta0, alpha)
      Ip_fit = Ip(beta0, alpha)
      sub_step[, ii] = c(Newton_fit$step, It_fit$step, Ip_fit$step)
      k1[[ii]] = Newton_fit$series
      k2[[ii]] = It_fit$series
      k3[[ii]] = Ip_fit$series
      sub_direction[[ii]] = It_fit$direction
    }
    step[[i]] = sub_step
    sub_series[["Newton"]] = k1
    sub_series[["It"]] = k2
    sub_series[["Ip"]] = k3
    series[[i]] = sub_series
    direction[[i]] = sub_direction
  }
  step_all[[j]] = step
  series_all[[j]] = series
  direction_all[[j]] = direction
  j = j+1
}

i = 4
k = lapply(step_all[[i]], "[", 2, )
s = NULL
for(j in 1:length(k)){
  s = c(s, k[[j]])
}
mean(s)



k = step_all[[6]]
for(i in 1:10){
  print(mean(k[[i]][2, ]))
}


```

## Risk Prediction Model

```{r}
library(MASS)
library(nleqslv)

# 数据生成
sim.gen.STM = function(n,p,beta0,sigmaZ,Nperturb=0)
{
  Z = mvrnorm(n,rep(0,p),sigmaZ^2*(0.2+0.8*diag(1,p)))
  u = runif(n)
  T = exp((log(u/(1-u)) - Z%*%beta0)/3)*4 #h^-1 (g^-1(u) - beta'Z)
  C = runif(n,0,12)
  delta = (T<=C)
  
  return(list(delta = delta, C = C, 
              Z = Z))
}

# 计算Psi和Phi
f = function(parameters, delta, Z, KC, N, p)
{ 
  # parameters contain beta and h
  beta = parameters[1:p]
  h = parameters[-(1:p)]
  pi = function(x) return(1/(1+exp(-x)))
  
  line = Z %*% beta
  # line is a N*1 vector
  
  reg = outer(h, line, "+")[,,1]
  reg_pi = pi(reg)
  # reg is a N*N matrix
  
  dif = as.vector(delta) - t(reg_pi)
  f1 = Z * diag(dif)
  f1 = apply(f1, 2, sum)
  f2 = KC * dif
  f2 = apply(f2, 2, sum)
  
  return(c(f1, f2))
}

# IP实现
implicit.profile = function(delta,Z, KC, init = rep(0,ncol(Z)), tol=1e-7,
                            maxit = 100, min.factor = 0.75,
                            ls.factor = 0.75, max.move = 1,
                            h.loop = T)
{
  start = Sys.time()
  n = nrow(Z)
  KCd = drop(KC%*%delta)
  hC = rep(0,n)
  oldscore = NULL
  
  #
  #f_path =NULL
  
  for(k in 1:maxit) 
  {
    lp = drop(Z%*%init)
    hC.flag = rep(TRUE,n)
    gij = wZbar = matrix(0,n,n)
    hHess = rep(0,n)
    for(kk in 1:ifelse(h.loop, maxit, 1))
    {
      # print(hC[hC.flag])
      gij[hC.flag,] = expit(outer(hC[hC.flag],lp,"+"))
      tmp = KC[hC.flag,]*gij[hC.flag,]
      wZbar[hC.flag,] = tmp*(1-gij[hC.flag,])
      if(sum(hC.flag)>=2)
      {
        hscore = apply(tmp,1,sum)-KCd[hC.flag]
        hHess[hC.flag] = apply(wZbar[hC.flag,],1,sum)
      }else
      {
        hscore = sum(tmp)-KCd[hC.flag]
        hHess[hC.flag] = sum(wZbar[hC.flag,])
      }
      
      dhC = hscore/hHess[hC.flag]
      dhC = sign(dhC)*pmin(abs(dhC),max.move)
      kk.flag = abs(hscore) > tol
      if(!any(kk.flag))
        break
      hC[hC.flag][kk.flag] = hC[hC.flag][kk.flag] - dhC[kk.flag]
      hC.flag[hC.flag] = kk.flag
    }
    if(kk >= maxit)
      stop("Numerical error when computing h0(Ci)")
    Zbar =  (wZbar%*%Z) / hHess 
    
    gi = expit(hC+lp)
    bscore = drop(t(Z)%*% (delta - gi))
    
    
    #
    #f_path = cbind(f_path, abs(bscore))
    
    if(!is.null(oldscore))
      if(((sum(oldscore^2)*min.factor) <= sum(bscore^2)))
      {
        init = init+dinit
        dinit = dinit*ls.factor
        if(max(abs(dinit))<tol)
        {
          if(max(abs(oldscore)) > 1e-6)
            warning(paste("Algorithm stops in line-search. Target tol: ",
                          tol, ". Current tol: ", max(abs(oldscore)),
                          ". ", sep = ''))
          break
        }
        init = init - dinit
        next
      }
    oldscore = bscore
    bHess = t(gi*(1-gi)*Z) %*% (Zbar-Z)
    dinit = solve(bHess,bscore)
    if(all(abs(bscore)<tol))
      break
    # print(rbind(init,bscore,dinit))
    init = init - dinit
  }
  if(k >=maxit)
    stop("Numerical error when computing beta_delta")
  
  run.time = Sys.time() - start
  return(list(beta = init, 
              run.time = run.time, 
              step = k))
}

# It实现
iterative = function(delta,Z, KC, tol=1e-7,
                          maxit = 100, h.maxit = 1)
{
  start = Sys.time()
  beta = rep(0, ncol(Z))
  n = nrow(Z)
  KCd = drop(KC%*%delta)
  Zd = drop( t(Z) %*% delta)
  hC = rep(0, n)
  expit = function(d) return(1/(1+exp(-d)))
  
  #
  #f_path = NULL
  
  f_beta = function(beta, hC, gi){
    temp_pi =t(Z) %*% gi
    return(Zd - temp_pi)
  }
  
  jacf_beta = function(beta, hC, gi){
    bHess = t(gi*(1-gi)*Z) %*% Z
    return(-bHess)
  }
  
  f_hC = function(hC, beta, gij, temp){
    return(apply(temp, 1, sum) - KCd)
  }
  
  jacf_hC = function(hC, beta, gij, temp){
    wZbar = temp*(1-gij)
    hscore = apply(temp,1,sum)-KCd
    hHess = apply(wZbar,1,sum)
    hHess = diag(hHess)
    return(hHess)
  }
  
  for(k in 1:maxit){
    gi = expit(hC + drop(Z %*% beta))
    temp_beta = nleqslv(beta, f_beta, jac = jacf_beta, 
                        hC = hC, gi = gi,method = "Newton", 
                        global = "none", control = list(maxit = 1))
    
    gij = matrix(0, nrow = n, ncol = n)
    gij[1:n, ] = expit(outer(hC, Z %*% temp_beta$x, "+"))
    temp = KC * gij
    temp_hC = nleqslv(hC, f_hC, jac = jacf_hC, 
                      beta = temp_beta$x, gij = gij, temp = temp, method = "Newton", 
                      global = "none", control = list(maxit = h.maxit))
    # print(k)
    if(all(abs(temp_beta$fvec) < tol))
      break
    
    #
    #f_path = cbind(f_path, abs(temp_beta$fvec))
    
    beta = temp_beta$x
    hC = temp_hC$x
  }
  
  runtime = Sys.time() - start
  return(list(beta = beta,
              run.time = runtime,
              step = k
  ))
}

# 牛顿法实现
global = function(init, f, delta, Z, KC, N, p){
  t0 = Sys.time()
  out = nleqslv(init, f, delta = delta, Z = Z, KC = KC,
                N = N, p = p, method = "Newton", global = "none")
  run.time = Sys.time() - t0
  return(list(Model = out, run.time = run.time))
}

```

```{r}


# simulation
nrep = 100
N = 1000
p = 10
beta0 = c(0.7,0.7,0.7,-0.5,-0.5,-0.5,0.3,0.3,0.3,0)
sigmaZ = 1
compare = list()
time = matrix(nrow = nrep, ncol = 3)
step = matrix(nrow = nrep, ncol = 3)
mse_global = 0
mse_IP = 0
mse_IT = 0
for(i in 1:nrep){
  dat = sim.gen.STM(N,p,beta0,sigmaZ)
  h = sd(dat$C)/(sum(dat$delta))^0.25
  KC = dnorm(as.matrix(dist(dat$C/h,diag=T,upper=T)))/h
  out_global = global(rep(0, N+p), f, dat$delta, dat$Z, KC, N , p)
  out_ip = implicit.profile(dat$delta, dat$Z, KC, h.loop = F)
  out_it = iterative(dat$delta, dat$Z, KC)
  mse_global = mse_global + sum((out_global$Model$x[1:p] - beta0)^2)
  mse_IP = mse_IP + sum((out_ip$beta - beta0)^2)
  mse_IT = mse_IT + sum((out_it$beta - beta0)^2)
  time[i, ] = c(out_global$run.time, out_ip$run.time, out_it$run.time)
  step[i, ] = c(out_global$Model$iter, out_ip$step, out_it$step)
  compare[[i]] = rbind(out_global$Model$x[1:p], out_ip$beta, out_it$beta)
  cat("step", i, sum(abs(out_global$Model$x[1:p] - out_ip$beta)),
      sum(abs(out_global$Model$x[1:p] - out_it$beta)), "\n")
}
apply(time, 2, mean)
apply(step, 2, mean)
(mse_global = mse_global/nrep)
(mse_IP = mse_IP/nrep)
(mse_IT = mse_IT/nrep)

```


## GARCH-M

```{r}
require(splines2)
require("BB")

# ===========================
# ====== Back Fitting =======
# ===========================

# 估计sigma
series_cal = function(y, init, sigma_1){
  N = length(y)
  sigma = vector(length = N)
  sigma[1] = sigma_1
  for(i in 2:N){
    sigma[i] = init[1] + init[2]*y[i-1]^2 + init[3]*sigma[i-1]
  }
  return(sigma)
}

# 计算样条矩阵
spline_matrix = function(sigma, knots, n_partitions){
  m = cbind(sigma, sigma^2)
  for(i in 1:n_partitions){
    k = sigma - knots[i]
    k[which(k < 0)] = 0
    m = cbind(m, k^2)
  }
  return(m)
}

# 计算Psi
M = function(init_est, y, epsilon, sigma_1){
  sigma = series_cal(y, init_est, sigma_1)
  
  k1 = -1/2*sum(log(sigma))
  k2 = -1/2*sum(epsilon^2/sigma)
  return(-(k1 + k2))
}

# Backfitting 实现
bf = function(y, init = rep(1, 3),
              sigma_1 = var(y), tol = 1e-5, maxiter = 20, lower = 1e-3, upper = 1
              , judge_k = F) 
{
  key = init
  t1 = Sys.time()
  step = 1
  N = length(y)
  n_partitions = floor(N^(3/20))
  
  judge = TRUE
  judge_covergence = TRUE
  
  while(judge) {
    sigma = series_cal(y, init, sigma_1)
    
    # if(any(sigma <= 0)) warning("sigma <= 0")
    
    k = range(sigma)
    knots = seq(k[1], k[2], length.out = n_partitions+2)
    knots = knots[c(-1, -length(knots))]
    # sigma_m = spline_matrix(sigma, knots = knots, n_partitions)
    sigma_m = bSpline(sigma, knots = knots, degree = 2)
    eta_out = lm(y ~ sigma_m)
    eta = predict(eta_out)
    
    epsilon = y - eta
    
    # sigma_try = series_cal(eta, init, sigma_1)
    
    # if(step <= 1){
    #   lm_out = lm(sigma[2:N]~y[1:(N-1)]^2 + sigma[1:(N-1)])
    #   init = lm_out$coefficients
    # }
    
    init_out = BBoptim(init, M, y = y, sigma_1 = sigma_1, epsilon = epsilon, lower = lower
                       , upper = upper
                       , control = list(maxit = 1500, gtol = tol, ftol = tol^2))
    
    if(init_out$convergence > 0) judge_covergence = FALSE
    if(judge_k & (init_out$iter> 1500)){
      judge_covergence = FALSE
    }
    
    
    if(max(abs(init_out$par-init)) < tol) judge = FALSE
    
    cat(step, init - init_out$par, init_out$convergence,"\n")
    # if(any(init_out$x <= 0)) {
    #   k = init_out$x
    #   k[which(k <= 0)] = init[which(k <= 0)]
    #   init = k
    # }else{
    #   init = init_out$x
    # }
    
    # if(init)
    init = init_out$par
    step = step + 1
    if(step > maxiter) judge = FALSE
  }
  if(step > maxiter) judge_covergence = FALSE
  sigma = series_cal(y, init, sigma_1)
  run.time = Sys.time()-t1
  result = list()
  result$beta = init
  result$eta = eta
  result$sigma = sigma
  result$run.time = run.time
  result$step = step
  result$judge_covergence = judge_covergence
  
  return(result)
}

# =================================
# =========== SP-MBP ==============
# =================================

# 估计sigma
series_cal = function(y, init, sigma_1){
  N = length(y)
  sigma = vector(length = N)
  sigma[1] = sigma_1
  for(i in 2:N){
    sigma[i] = init[1] + init[2]*y[i-1]^2 + init[3]*sigma[i-1]
  }
  return(sigma)
}

# 计算样条矩阵
spline_matrix = function(sigma, knots, n_partitions){
  m = cbind(sigma, sigma^2)
  for(i in 1:n_partitions){
    k = sigma - knots[i]
    k[which(k < 0)] = 0
    m = cbind(m, k^2)
  }
  return(m)
}


# 计算Psi
M_sp = function(init_est, y, epsilon, sigma_1, Psi2, n_partitions){
  sigma = series_cal(y, init_est, sigma_1)
  k1 = -1/2*sum(log(sigma))
  k2 = -1/2*sum(epsilon^2/sigma)
  
  k = range(sigma)
  knots = seq(k[1], k[2], length.out = n_partitions+2)
  knots = knots[c(-1, -length(knots))]
  sigma_m = bSpline(sigma, knots = knots, degree = 2)
  
  eta_out = lm(y ~ sigma_m)
  eta = predict(eta_out)
  
  k3 = Psi2 %*% init_est
  
  return(-(k1+k2+k3))
}


Psi_2_B = function(y, init, sigma, epsilon, knots) {
  
  init_dsigma = rep(0, 3)
  dsigma = matrix(0, nrow = length(y), ncol = 3)
  dsigma[1, ] = init_dsigma
  
  for(i in 2:length(sigma)){
    dsigma[i, ] = c(1, y[i-1]^2, sigma[i-1]) + init[3]*dsigma[(i -1), ]
  }
  
  sigma_d = dbs(sigma, knots = knots, degree = 2)
  eta_d = lm(y~sigma_d)
  eta_d = predict(eta_d)
  eta_d = eta_d*dsigma
  
  output = apply(epsilon/sigma *eta_d, 2, sum)
  
  return(output)
}

# SPMBP实现
spmbp_B = function(y, init = rep(1, 3),
                   sigma_1 = var(y), tol = 1e-5, maxiter = 20, lower = 1e-3, upper = 1
                   , judge_k = F) 
{
  key = init
  t1 = Sys.time()
  step = 1
  N = length(y)
  n_partitions = floor(N^(3/20))
  
  judge = TRUE
  judge_covergence = TRUE
  
  while(judge) {
    sigma = series_cal(y, init, sigma_1)
    
    # if(any(sigma <= 0)) warning("sigma <= 0")
    
    k = range(sigma)
    knots = seq(k[1], k[2], length.out = n_partitions+2)
    knots = knots[c(-1, -length(knots))]
    sigma_m = bSpline(sigma, knots = knots, degree = 2)
    
    eta_out = lm(y ~ sigma_m)
    eta = predict(eta_out)
    
    epsilon = y - eta
    
    # sigma_try = series_cal(eta, init, sigma_1)
    Psi2 = Psi_2_B(y, init, sigma, epsilon, knots)
    # if(step <= 1){
    #   lm_out = lm(sigma[2:N]~y[1:(N-1)]^2 + sigma[1:(N-1)])
    #   init = lm_out$coefficients
    # }
    
    
    init_out = BBoptim(init, M_sp, y = y, sigma_1 = sigma_1, epsilon = epsilon
                       , n_partitions = n_partitions
                       , Psi2 = Psi2, lower = 1e-3, upper = upper
                       , control = list(maxit = 1500, gtol = tol, ftol = tol^2))
    
    if(init_out$convergence > 0) judge_covergence = FALSE
    if(judge_k & (init_out$iter > 1500)) {
      judge_covergence = FALSE
    }
    
    if(max(abs(init_out$par-init)) < tol) judge = FALSE
    
    cat(step, init - init_out$par, init_out$convergence,"\n")
    init = init_out$par
    
    step = step + 1
    if(step > maxiter) judge = FALSE
  }
  if(step > maxiter) judge_covergence = FALSE
  
  sigma = series_cal(y, init, sigma_1)
  run.time = Sys.time()-t1
  result = list()
  result$beta = init
  result$eta = eta
  result$sigma = sigma
  result$run.time = run.time
  result$step = step
  result$judge_covergence = judge_covergence
  
  return(result)
}


# ===========================
# ====== IP-GARCH ===========
# ===========================

M_ip_BB = function(init_est, y, sigma_1, n_partitions){
  sigma = series_cal(y, init_est, sigma_1)
  k = range(sigma)
  knots = seq(k[1], k[2], length.out = n_partitions+2)
  knots = knots[c(-1, -length(knots))]
  sigma_m = bSpline(sigma, knots = knots, degree = 2)
  
  eta_out = lm(y ~ sigma_m)
  eta = predict(eta_out)
  
  epsilon = y - eta
  
  k1 = -1/2*sum(log(sigma))
  k2 = -1/2*sum(epsilon^2/sigma)
  
  return(-(k1+k2))
}

IP_GARCH_BB = function(y, init = rep(1, 3),
                    sigma_1 = var(y), tol = 1e-5, maxiter = 20, lower = 1e-3, upper = 1
                    , judge_k = F)
{
  key = init
  t1 = Sys.time()
  step = 1
  N = length(y)
  n_partitions = floor(N^(3/20))
  
  judge = TRUE
  judge_covergence = TRUE
  
  # while(judge){
    init_out = BBoptim(init, M_ip_BB, y = y, sigma_1 = sigma_1
                       , n_partitions = n_partitions, lower = 1e-3, upper = upper
                       , control = list(maxit = 1500, ftol = tol^2,
                                        gtol = tol))
    
    
    
    if(init_out$convergence > 0) judge_covergence = FALSE
    if(judge_k & init_out$iter> 1500){
      judge_covergence = FALSE
    }
    
    if(sum((init_out$par-init)^2) < tol) judge = FALSE
    
    cat(step, init - init_out$par, init_out$convergence,"\n")
    init = init_out$par
    
    step = step + 1
    if(step > maxiter) judge = FALSE
  # }
  
  if(step > maxiter) judge_covergence = FALSE
  
  sigma = series_cal(y, init, sigma_1)
  run.time = Sys.time()-t1
  result = list()
  result$beta = init
  # result$eta = eta
  result$sigma = sigma
  result$run.time = run.time
  result$step = step
  result$judge_covergence = judge_covergence
  
  return(result)
}
```

```{r}

# =================================
# ========== simulation ===========
# =================================

# A数据生成
series_gen = function(N, y1, init, sigma1){
  y = vector(length = N)
  sigma = vector(length = N)
  y[1] = y1
  sigma[1] = sigma1
  
  for(i in 2:N){
    sigma[i] = init[1] + init[2] * y[i-1]^2 + init[3] * sigma[i-1]
    y[i] = sigma[i] + 0.5 * sin(10 * sigma[i]) + sqrt(sigma[i])*rnorm(1)
  }
  
  return(y)
}

# B数据生成
series_gen2= function(N, y1, init, sigma1){
  y = vector(length = N)
  sigma = vector(length = N)
  y[1] = y1
  sigma[1] = sigma1
  
  for(i in 2:N){
    sigma[i] = init[1] + init[2] * y[i-1]^2 + init[3] * sigma[i-1]
    y[i] = 0.5*sigma[i] + 0.1 * sin(0.5 + 20 * sigma[i]) + sqrt(sigma[i])*rnorm(1)
  }
  
  return(y)
}

```



